---
title: "Homework 6"
author: "Constantine Kutson"
date: "10/23/2022"
output: pdf_document
---

```{r include=FALSE}
library(tidyverse)
library(knitr)
library(outliers)
library(corrplot)
library(pls)
library(glmnet)
library(caret)
library(Metrics)
library(readxl)
```

```{r include=FALSE}
## Importing data
Train <- read.csv("~/Documents/Graduate School/Year 2/DSA5103/Homework 6/Train.csv")
Test <- read.csv("~/Documents/Graduate School/Year 2/DSA5103/Homework 6/Test.csv")

## Renaming variables
Train <- Train %>% 
  dplyr::rename(adWordsPageNum = adwordsClickInfo.page,
         adWordsPosition = adwordsClickInfo.slot,
         adWordsClickID = adwordsClickInfo.gclId,
         adWordsNetworkType = adwordsClickInfo.adNetworkType,
         adWordsVideoAd = adwordsClickInfo.isVideoAd)
```

## Problem 1: Data Understanding
#### Charachter Data Quality Report

```{r include=FALSE}
#### Generating Character Data Quality Report ####
Character_Variables <- Train %>% 
    dplyr::select(channelGrouping, browser, operatingSystem, deviceCategory,
         continent, subContinent, country, region, metro, city, networkDomain,
         campaign, source, medium, keyword, referralPath, adContent, adWordsPosition,
         adWordsClickID, adWordsNetworkType)

Chr_Observations <- rbind(sum(Character_Variables$channelGrouping != ""),
      sum(Character_Variables$broswer != ""),
      sum(Character_Variables$operatingSystem != ""),
      sum(Character_Variables$deviceCategory != ""),
      sum(Character_Variables$continent != ""),
      sum(Character_Variables$subContinent != ""),
      sum(Character_Variables$country != ""),
      sum(Character_Variables$region != ""),
      sum(Character_Variables$metro != ""),
      sum(Character_Variables$city != ""),
      sum(Character_Variables$networkDomain != ""),
      sum(Character_Variables$campaign != ""),
      sum(Character_Variables$source != ""),
      sum(Character_Variables$medium != ""),
      sum(Character_Variables$keyword != ""),
      sum(Character_Variables$referralPath != ""),
      sum(Character_Variables$adContent != ""),
      sum(Character_Variables$adWordsPosition != ""),
      sum(Character_Variables$adWordsClickID != ""),
      sum(Character_Variables$adWordsNetworkType != ""))

Chr_Observations[2] <- 70070

Chr_Variables <- c("channelGrouping", "browser", "operatingSystem", "deviceCategory",
         "continent", "subContinent", "country", "region", "metro", "city",  "networkDomain", "campaign", "source", "medium", "keyword", "referralPath", "adContent", "adWordsPosition", "adWordsClickID", "adWordsNetworkType")
  
N_Chr <- cbind(Chr_Variables, Chr_Observations)
N_Chr <- as.data.frame(N_Chr)
N_Chr <- transform(N_Chr, Chr_Observations = as.numeric(Chr_Observations))

Unique_Chr_Variables <- rapply(Character_Variables,function(x)length(unique(x)))

Character_Data_Report <- N_Chr %>% 
  rename(N = Chr_Observations) %>% 
  cbind(Unique_Chr_Variables) %>% 
  mutate(Missing = (70071 - N),
         Missing_Pct = (100 * (Missing / 70071)),
         Missing_Pct = round(Missing_Pct, digits = 1),
         Unique_Pct = ((Unique_Chr_Variables / N) * 100),
         Unique_Pct = round(Unique_Pct, digits = 1)) %>% 
  dplyr::select(-Chr_Variables, -V2)
  
```

```{r echo=FALSE}
Character_Data_Report %>% kable()
```

#### Numeric Data Quality Report

```{r include=FALSE}
Numeric_Variables <- dplyr::select_if(Train, is.numeric)
Numeric_NA <- colSums(is.na(Numeric_Variables))
Numeric_Colnames <- colnames(Numeric_Variables)
Numeric_Rows <- c(70071, 70071, 70071, 70071, 70071,
                  70071, 70071, 70071, 70071, 70071,
                  70071, 70071)
N_Nur <- cbind(Numeric_Colnames, Numeric_Rows, Numeric_NA)
N_Nur <- as.data.frame(N_Nur)
N_Nur <- transform(N_Nur, Numeric_NA = as.numeric(Numeric_NA),
                   Numeric_Rows = as.numeric(Numeric_Rows))

Unique_Nur_Variables <- rapply(Numeric_Variables,function(x)length(unique(x)))

Numeric_Data_Report <- N_Nur %>% 
  cbind(Unique_Nur_Variables) %>% 
  mutate(Missing_Pct = ((Numeric_NA/Numeric_Rows) * 100),
         Unique_Pct = ((Unique_Nur_Variables / Numeric_Rows) * 100),
         Missing_Pct = round(Missing_Pct, digits = 1),
         Unique_Pct = round(Unique_Pct, digits = 1)) %>% 
  dplyr::select(-Numeric_Colnames) %>% 
  rename(N = Numeric_Rows,
         Missing = Numeric_NA,
         "Unique Values" = Unique_Nur_Variables,
         "Missing Percentage" = Missing_Pct,
         "Unique Percentage" = Unique_Pct)
```

```{r echo=FALSE}
Numeric_Data_Report %>% kable()
```

#### Visualizations

I chose the following visualizations for a few reasons. The correlation matrix was selected after a number of trial and error visualizations, and it was selected because it gave me a good starting point for picking potential predictor variables in my OLS model. Indeed, both of the variables that were shown to be correlated with revenue made it into the final model. 

The histograms were also chosen to demonstrate the effect of skewed data and log transforming on this assignment. Almost none of the data was normally distributed, and it made it very difficult to build models without prior data preparation. While I ended up log transforming many of the variables, these were ultimately chose because it demonstrated the effect of log transformation on the most important variable, that being revenue. 


```{r include=FALSE}
Cor_Customer <- Train %>% 
  group_by(custId) %>% 
  summarise(totalRevenue = sum(revenue),
            totalPageViews = sum(pageviews),
            totalVisits = max(visitNumber),
            isMobile = isMobile) %>% 
   mutate(totalPageViews = log(totalPageViews)) %>% 
   #      totalVisits = log(totalVisits),
    #     totalRevenue = log(totalRevenue)) %>% 
 distinct(custId, .keep_all = TRUE)

Cor_Customer <- cor(Cor_Customer)
```

```{r echo=FALSE, fig.align='center'}
corrplot::corrplot(Cor_Customer)
```

```{r echo=FALSE}
p1 <- hist(Train$revenue)
Log_Transformed_Revenue <- Train %>% 
  select(revenue, custId) %>% 
  group_by(custId) %>% 
  mutate(totalRevenue = log(revenue))
p3 <- hist(Log_Transformed_Revenue$totalRevenue, xlim = c(0,10))
```

## Problem 2: Data Preparation

There were a number of critical data preparation steps that were taken in order to prepare the data for modeling. First and foremost, the removal of outliers and the log transformation of the revenue variable was probably the most important. There were a great number of outliers in the revenue column, and as a result, made modeling very challenging. Even once the outliers were removed, the data was still heavily skewed to the left, so it was log transformed in order to give it a more normal distribution. 

Another key component of the data preparation process was the grouping of variables by customer ID. Before modeling, I aggregated all key variables for each customer. For example, a customer who visited multiple times would have the sum of his revenue calculated, total page views summed, and the total number of visits summed in order to give one observation per customer. This made modeling significantly easier, and it improved the performance of my models as well. Lastly, these variables were also log transformed. 

```{r include=FALSE}
## Removing Columns With Too Much Missing Data
Train <- Train %>% 
  dplyr::select(-c(adWordsPageNum, region, metro, city, networkDomain, topLevelDomain, campaign,
                   source, medium, keyword, referralPath, adContent, adWordsPosition, adWordsClickID,
                   adWordsNetworkType, adWordsVideoAd, bounces, newVisits))

## Filling NA page values with the mean for all values
Train$pageviews[is.na(Train$pageviews)]<-mean(Train$pageviews,na.rm=TRUE)

## Converting Relevant Columns to factors
 Train[sapply(Train, is.character)] <- lapply(Train[sapply(Train, is.character)], 
                                       as.factor)

## Removing outliers
Train <- Train %>% 
  filter(revenue >= 1) %>% 
  mutate(revenue = log(revenue))

## Refining training data to remove outliers and only look at relevant variables
Train2 <- Train %>% 
  filter(revenue >= 1, revenue < 200) %>% 
  select(custId, visitStartTime, visitNumber, timeSinceLastVisit, isMobile, pageviews,
         revenue, continent, channelGrouping)

## Aggregating numeric and selected factor variables on a per customer basis
Train_Per_Customer <- Train2 %>% 
  group_by(custId) %>% 
  summarise(totalRevenue = sum(revenue),
            totalPageViews = sum(pageviews),
            totalVisits = max(visitNumber),
            channelGrouping = channelGrouping,
            isMobile = isMobile) %>% 
  mutate(totalPageViews = log(totalPageViews),
         totalVisits = log(totalVisits),
         totalRevenue = log(totalRevenue)) %>% 
 distinct(custId, .keep_all = TRUE)

```

## Problem 3: Modeling

The code that was used to design and build these models can be found in the PDF. Below is a table summary of all of the constructed models. All models used a cross-validation approach to resampling. 

```{r include=FALSE}
## Ordinary Least Squares Model
OLS1 <- lm(data = Train_Per_Customer, totalRevenue ~ totalPageViews * totalVisits * isMobile * channelGrouping)
summary(OLS1)

Test2 <- Test %>% 
  select(custId, visitStartTime, visitNumber, timeSinceLastVisit, isMobile, pageviews, channelGrouping)

Test2$pageviews[is.na(Test2$pageviews)]<-mean(Test2$pageviews,na.rm=TRUE)

## Refining testing data for model fit

Test_Model <- Test2 %>% 
  group_by(custId) %>% 
  summarise(totalPageViews = sum(pageviews),
            totalVisits = max(visitNumber),
            isMobile = isMobile,
            channelGrouping = channelGrouping) %>% 
  mutate(totalPageViews = log(totalPageViews),
         totalVisits = log(totalVisits)) %>% 
   distinct(custId, .keep_all = TRUE)

Test_Model$channelGrouping[Test_Model$channelGrouping == "(Other)"] <- "Affiliates"

## Converting country to factor variable
Test_Model[sapply(Test_Model, is.character)] <- lapply(Test_Model[sapply(Test_Model, is.character)], 
                                       as.factor)

## Filling NA's with mean of column
Test_Model$totalPageViews[is.na(Test_Model$totalPageViews)]<-mean(Test_Model$totalPageViews,na.rm=TRUE)


predRevenue <- predict(OLS1, Test_Model)
predRevenue <- as.data.frame(predRevenue)
custId <- Test_Model$custId
Submission <- cbind(custId, predRevenue)
plot(Submission)

write.csv(Submission,"~/Desktop/OLS_Submission.csv", row.names = FALSE)
```

```{r include=FALSE}
## Calculation of R2 and RMSE for OLS
set.seed(1)

sample <- sample(c(TRUE, FALSE), nrow(Train_Per_Customer), replace=TRUE, prob=c(0.7,0.3))
test_1  <- Train_Per_Customer[sample, ]
train_1   <- Train_Per_Customer[!sample, ]

OLS1 <- lm(data = Train_Per_Customer, totalRevenue ~ totalPageViews * totalVisits * isMobile * channelGrouping)
summary(OLS1)

actual_test1_values <- test_1$totalRevenue

test_1_OLS <- test_1 %>% 
  select(-totalRevenue)

predicted_test1_values <- predict(OLS1, test_1)

sqrt(mean((actual_test1_values - predicted_test1_values)^2))
```

```{r include=FALSE}
## PCR Regression 
PCR_Per_Customer <- train_1

PCR_Test <- test_1

PCR_Per_Customer[sapply(PCR_Per_Customer, is.character)] <- lapply(PCR_Per_Customer[sapply(PCR_Per_Customer, is.character)], as.factor)
PCR_Test[sapply(PCR_Test, is.character)] <- lapply(PCR_Test[sapply(PCR_Test, is.character)], as.factor)

PCR_Regression <- pcr(totalRevenue~., data = PCR_Per_Customer, validation = "CV")
summary(PCR_Regression)
validationplot(PCR_Regression)
PCR_Prediction <- predict(PCR_Regression, PCR_Test, ncomp = 10)
summary(PCR_Prediction)
rmse(actual = PCR_Test$totalRevenue, predicted = as.numeric(PCR_Prediction))
```

```{r include=FALSE}
## Elastic Net Regression
en_regression <- train(totalRevenue~., method = "glmnet", data = train_1,
                       tuneGrid = expand.grid(alpha = seq(0,1, length = 10),
                                              lambda = seq(0.1, 1, length = 10)))

en_regression
plot(en_regression)

en_prediction <-  predict(en_regression, test_1)
rmse(actual = test_1$totalRevenue, predicted = en_prediction)
cor(test_1$totalRevenue, en_prediction)
sqrt(cor(test_1$totalRevenue, en_prediction))
summary(en_regression)
```

```{r include=FALSE}

ridge_regression <- train(totalRevenue ~., data = train_1, method = "glmnet",
                          tuneGrid = expand.grid(alpha = 0,
                                                 lambda = seq(0.5, 1, length = 10)))

plot(ridge_regression)

ridge_prediction <-  predict(ridge_regression, test_1)
rmse(actual = test_1$totalRevenue, predicted = ridge_prediction)
cor(test_1$totalRevenue, ridge_prediction)
sqrt(cor(test_1$totalRevenue, ridge_prediction))
summary(ridge_regression)
```

```{r include=FALSE}
Model_Summary <- read_excel("Model_Summary.xlsx")
```

```{r echo=FALSE}
Model_Summary %>% kable()
```


## Problem 4: Debrief

Overall, I found this assignment to be extremely challenging but also greatly informative. Even though I was not able to beat the benchmark score on the Kaggle competition, I still learned a lot through the course of the competition and assignment. My best performing model was the OLS model, which makes sense as I spent the most time refining it for the competition. 

To begin, I examined correlations and saw what was potentially correlated with revenue. From there, I placed those numeric variables in the regression equation as predictor variables. Once I had those in place, I began to look at interaction effects, and found that certain interactions improved the performance of my model. From here it became very challenging, as I began to incorporate factor variables. A lot of them had a great deal of missing data, so it was tough to pick ones that improved model performance. However, I ultimately decided on mobile device usage and channel grouping, as they had the greatest impact on R2 and RMSE. 

One of my biggest problems during the modeling challenge was thinking of new ways to approach the problem and refine the model; especially once I got myself down a rabbit hole trying to figure out a solution in a certain way. There were a number of times I had to step back and restart to see where a new path would take me, and while I was never able to beat the benchmark I did significantly refine the model to get very close. 

Next time, I would probably try some sort of model stacking to further improve performance as well as take a further look at the preprocessing step. 